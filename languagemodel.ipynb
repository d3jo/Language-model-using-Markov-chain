{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joaju\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pandas\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the whole story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines :  215663\n"
     ]
    }
   ],
   "source": [
    "story_path = \"/Users/joaju/OneDrive/LanguageModel/SherlockZip/sherlock/sherlock/\"\n",
    "\n",
    "# Reads in all of the textfile from the path and stores it in a list;\n",
    "\n",
    "def read_story(story_path):\n",
    "    txt = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(story_path+file) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line != '':\n",
    "                        txt.append(line)\n",
    "\n",
    "    return txt\n",
    "\n",
    "story = read_story(story_path)\n",
    "print(\"Number of lines : \", len(story))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter non-english alphabetic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words =  2337745\n"
     ]
    }
   ],
   "source": [
    "# Remove non alphabet characters from the txt since we are only interested\n",
    "# in feeding english words.\n",
    "# Tokenizing : Converting words in to each state is tokenizing.\n",
    "\n",
    "def clean_txt(txt):\n",
    "    cleaned_txt = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_txt += words\n",
    "    return cleaned_txt\n",
    "\n",
    "cleaned_story = clean_txt(story)\n",
    "print(\"number of words = \", len(cleaned_story))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov model is essentially a graph model, that has many different vertices\n",
    "which we call each a \"state\". Each state in this graph represents a single pair of\n",
    "words and the edges that connect these states have weights equivalent to how many times they appear adjacently in the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_model(cleaned_story, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_story)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_story[i+j] + \" \" # current state is a set of n_gram words\n",
    "            next_state += cleaned_story[i+j+n_gram] + \" \" # set the next state\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model: # include this word in dictionary if not existent\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1 # Start counting the number of appearance\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1 # Increment the number of times next_state came after current state\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "\n",
    "        \n",
    "    # Calculating transition probabilities\n",
    "    # By dividing the counted values by total transition values.\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count / total\n",
    "\n",
    "    return markov_model\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain = markov_model(cleaned_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states =  208801\n"
     ]
    }
   ],
   "source": [
    "print(\"number of states = \", len(markov_chain.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible transitions from the state 'the game' : \n",
      "\n",
      "{'your letter': 0.02702702702702703, 'was up': 0.09009009009009009, 'is afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'in their': 0.036036036036036036, 'was whist': 0.036036036036036036, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was afoot': 0.036036036036036036, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "print(\"All possible transitions from the state 'the game' : \\n\")\n",
    "print(markov_chain['the game'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random Sherlock holmes story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(markov_chain, start, limit = 100):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story += curr_state + \" \"\n",
    "    while n < limit:\n",
    "        next_state = random.choices(list(markov_chain[curr_state].keys()),\n",
    "                                    list(markov_chain[curr_state].values()))\n",
    "        curr_state = next_state[0]\n",
    "        story += curr_state + \" \"\n",
    "        n += 1\n",
    "    return story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . dear holmes he has some very sharp instrument it was some distance up the small winding which led \n",
      "2 . i fear your servant miss morstan he kept his hound to treat them you may be from him \n",
      "3 . this means that there is a mr john douglas at all but one thing while they marched in \n",
      "4 . that there is pain for you my man however it chanced that even when the moriarty gang was \n",
      "5 . on that particular night seven years and the child likewise let it proceed by all means so long \n",
      "6 . side a ridge of rocks ended in a very abstruse and complicated one but in any court i \n",
      "7 . blow was delivered with such intense earnestness that she could easily do in the hands of the enemy \n",
      "8 . struck and two and thirty pounds we shall reach some definite result let the public into my brother \n",
      "9 . one and two and i beg of you to ask about father but they were true but could \n",
      "10 . that i may place considerable confidence in mr holmes sir i am not a killing its early days \n",
      "11 . took the letters in the word lies now with you i should have some knowledge however theres no \n",
      "12 . liberty therefore of making an appointment with the note sherlock holmes gave an exclamation sprang to it and \n",
      "13 . of making up and into the matter his motives are more obscure surely you are mistaken about his \n",
      "14 . an appointment with the stone at once for phelpss room to find that the whole proceeding could hardly \n",
      "15 . with me i used to call asking for your criticism it is an impersonal thing a rose is \n",
      "16 . what though i was fond of queer mysteries and i implored him by his bitter grief that he \n",
      "17 . i was again conscious of that daughter that i would have made upon your notice give rise to \n",
      "18 . thinking the matter over and over here is my monograph upon the assessment of machinery the matter hardly \n",
      "19 . business over this youll remember that my poor watson here would prescribe a sedative however that they would \n",
      "20 . and trying to analyze my impressions i could see at a glance round what a charming room perhaps \n"
     ]
    }
   ],
   "source": [
    "start = 'dear holmes'\n",
    "for i in range(21)[1:]:\n",
    "    print(str(i), \".\", generate_story(markov_chain, start, limit=8))\n",
    "    start = random.choices(list(markov_chain[start].keys()))[0]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above 20 lines are randomly generated sentences using our markov model.\n",
    "It has utilized the graph data structure through dictionary to model the probability relationships between\n",
    "words that have shown up in Sherlock Holmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
